llm:
  default:
    provider: "openai"
    model: "gpt-5.1-2025-11-13"
    temperature: 0.2
  
  overrides:
    # watcher:
    #   provider: "openai"
    #   model: "Qwen3-VL-8B-Instruct"
    #   base_url: "http://localhost:8005/v1"
    #   api_key: "EMPTY"
    #   max_tokens: 1024
    # Example:
    # planner:
    #   temperature: 0.5
    # watcher:
    #   model: "gpt-3.5-turbo"

transcript:
  provider: "whisper" #  "oxylabs" | "local" | "ytdlp" | "whisper"

watcher:
  num_frames: 16
  video_downloader: "pytubefix" # "ytdlp" | "pytubefix"

selector:
  top_k: 3

planner:
  max_queries: 1

cache:
  enabled: true
  base_dir: "data/cache"

search:
  text_search_provider: null # "tavily" | "serper" | "duckduckgo" | null
  video_search_provider: "youtube" # "youtube" | "serper" | "duckduckgo"

checker:
  max_loop_steps: 3

logger:
  enabled: true
  log_dir: "data/logs"

prompts:
  analyst_format_instructions: |
    Your response should be in the following JSON format:
    {
        "Explanation": "your explanation for your final answer",
        "Answer": "your succinct, final answer",
        "Confidence": "your confidence score between 0% and 100% for your answer"
    }
